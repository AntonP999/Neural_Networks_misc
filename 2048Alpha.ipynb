{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "ikumCeWbkRlj",
    "outputId": "86e72a3f-7351-4e62-c4c0-078c2195c619"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "6hh61vOuzzpD",
    "outputId": "bed147fa-990e-48c1-d943-866f9917f24a"
   },
   "outputs": [],
   "source": [
    "PATH = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s0uMULEQkWIN"
   },
   "outputs": [],
   "source": [
    "param_join_reward = 1\n",
    "param_inv_move_reward = -8\n",
    "param_ohe_state = True\n",
    "param_input_shape = 4*4*14 if param_ohe_state else 4*4\n",
    "param_n_actions = 4\n",
    "param_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8XWuHir3kY6i"
   },
   "outputs": [],
   "source": [
    "# Направление хода -> оси\n",
    "directions_dict = {0: np.array((0,1)),\n",
    "                   1: np.array((1,0)),\n",
    "                   2: np.array((0,-1)),\n",
    "                   3: np.array((-1,0)),}\n",
    "\n",
    "# Направление в one-hot\n",
    "def dir_to_ohe(direction_int):\n",
    "    ohe = np.zeros(4)\n",
    "    ohe[direction_int] = 1\n",
    "    return ohe\n",
    "\n",
    "# Направление one-hot в int\n",
    "def ohe_to_dir(direction_ohe):\n",
    "    return np.argmax(direction_ohe)\n",
    "\n",
    "# Значение тайла в one-hot\n",
    "def tile_to_ohe(n):    \n",
    "    ohe = np.zeros(14)\n",
    "    if n>0:\n",
    "        n = int(np.log2(n))    \n",
    "        ohe[n-1] = 1\n",
    "    return ohe\n",
    "\n",
    "# Состояние в one-hot для нейросети\n",
    "def state_to_ohe(state):\n",
    "    ohe = np.zeros((4,4,14))\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            ohe[i,j] = tile_to_ohe(state[i,j])\n",
    "    return ohe.transpose((2,0,1))\n",
    "\n",
    "def position_to_tuple(position):\n",
    "    return tuple([tuple(x) for x in position])\n",
    "\n",
    "# Игровой движок\n",
    "class Game_Core_2048:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, random_start=0., max_number=128):\n",
    "        # Стандартное начало игры или со случайного состояния\n",
    "        self.gameboard = np.zeros((4, 4)).astype(int)\n",
    "        if np.random.rand() >= random_start:\n",
    "            self.place_random_number()\n",
    "            self.place_random_number()\n",
    "        else:\n",
    "            self.make_random_state(max_number)\n",
    "        #self.gameover = False\n",
    "        self.moves_dict = self.find_all_moves()\n",
    "        self.gameover = self.check_gameover(self.moves_dict)\n",
    "        self.score = 0\n",
    "        self.inv_move_count = 0\n",
    "\n",
    "    def random_free_cell(self):\n",
    "        # Возвращает случайную пустую ячейку\n",
    "        free_cells = np.argwhere(self.gameboard == 0)\n",
    "        return free_cells[np.random.randint(len(free_cells))]\n",
    "\n",
    "    def place_random_number(self):\n",
    "        # Добавление случайного тайла (по принципу как в оригинале)\n",
    "        n = 2 if np.random.rand() < 0.9 else 4\n",
    "        cell = self.random_free_cell()\n",
    "        self.gameboard[cell[0], cell[1]] = n\n",
    "\n",
    "    def place_number(self, position, state):\n",
    "        # Ставит значение в позицию (для MCTS). \n",
    "        state = state.copy()\n",
    "        free_cells = np.argwhere(state == 0)\n",
    "        number = 2\n",
    "        if position >= len(free_cells):\n",
    "            number = 4\n",
    "            position -= len(free_cells)\n",
    "        cell = free_cells[position]\n",
    "        state[cell[0], cell[1]] = number\n",
    "        moves_dict = self.find_all_moves(state)\n",
    "        state_gameover = self.check_gameover(moves_dict)\n",
    "        return state, state_gameover\n",
    "\n",
    "    def make_random_state(self, max_number):\n",
    "        # Генерирует случайную стартовую позицию.\n",
    "        idx = np.where(self.gameboard==0)\n",
    "        powers = np.random.randint(np.log2(max_number), size=(len(idx[0])))+1\n",
    "        mask = np.random.randint(2, size=(len(idx[0]))).astype(np.bool)\n",
    "        self.gameboard[idx] = 2**powers*mask\n",
    "\n",
    "    def find_moves(self, gameboard, direction, already_summed_mask, offset):\n",
    "        # Возвращает допустимые ходы в заданном направлении для заданного ряда/колонки.\n",
    "        # Пытался избежать вложенных циклов, как в оригинальной версии.\n",
    "        keep0 = []  # Хранение ходов - ось 0\n",
    "        keep1 = []  # Хранение ходов - ось 1\n",
    "        axis = np.argwhere(direction != 0)[0, 0]  # Ось направления\n",
    "        del_axis = int(not axis)  # Ось удаления найденных ходов\n",
    "\n",
    "        # Выбор параметров для горизонтального или вертикального направления.\n",
    "        if axis:\n",
    "            shape = (4, 1)\n",
    "            inds = np.indices(shape)\n",
    "            dirs = np.tile(direction[axis], 4).reshape(shape)\n",
    "            mask = np.ones(shape) # Маска для несдвигаемых тайлов.\n",
    "        else:\n",
    "            shape = (1, 4)\n",
    "            inds = np.indices(shape)\n",
    "            dirs = np.tile(direction[axis], 4).reshape(shape)\n",
    "            mask = np.ones(shape) # Маска для несдвигаемых тайлов.\n",
    "        \n",
    "        check_inds = inds.copy()  # Индексы для проверки доступного хода вдоль оси\n",
    "        check_inds[axis] = check_inds[axis] + offset  # Начало со смещения\n",
    "        mask = (mask * (gameboard[check_inds[0], check_inds[1]] != 0)).astype(bool)  # Нули не двигаем\n",
    "        keep0, keep1 = check_inds[0][mask == 0], check_inds[1][mask == 0]  # Сохранение перед удалением\n",
    "        if axis:\n",
    "            cur_values = gameboard[:, offset].reshape(shape)  # Сохранение текущих значений в ячейках\n",
    "        else:\n",
    "            cur_values = gameboard[offset, :].reshape(shape)  # Сохранение текущих значений в ячейках\n",
    "        cur_values_mask = np.ones(shape).astype(bool)\n",
    "        # Удаление из поиска того, что дальше не двигается.\n",
    "        check_inds = np.delete(check_inds, np.where(mask.flatten() == 0), axis=del_axis + 1)\n",
    "        dirs = np.delete(dirs, np.where(mask.flatten() == 0), axis=del_axis)\n",
    "        cur_values = np.delete(cur_values, np.where(mask.flatten() == 0), axis=del_axis)\n",
    "        cur_values_mask = np.delete(cur_values_mask, np.where(mask.flatten() == 0), axis=del_axis)\n",
    "        mask = np.delete(mask, np.where(mask.flatten() == 0), axis=del_axis)\n",
    "\n",
    "        # Пока что-то можно двигать дальше\n",
    "        while check_inds.size > 0:\n",
    "            cur_values[cur_values_mask] = gameboard[check_inds[0], check_inds[1]][cur_values_mask] # Сохранение текущих значений в ячейках\n",
    "            prev_inds = check_inds.copy()\n",
    "            check_inds[axis] = check_inds[axis] + dirs * mask # Смещение индексов для проверки на 1 по направлению.\n",
    "            mask = ((-direction[axis] * check_inds[axis]) >= 1 * (direction[axis] > 0)).astype(\n",
    "                bool)  # Проверка на границы поля\n",
    "            asm_mask = already_summed_mask[check_inds[0], check_inds[1]] == 0  # Проверка на уже суммированное значение (всегда первое по направлению)\n",
    "            mask = mask * asm_mask\n",
    "            new_values = gameboard[check_inds[0], check_inds[1]]  # Проверка на равенство\n",
    "            cur_values_mask = new_values != 0\n",
    "            mask_eq = mask * (cur_values == new_values)\n",
    "            mask_free = mask * (gameboard[check_inds[0], check_inds[1]] == 0)  # Проверка на свободную ячейку\n",
    "            mask = mask_eq + mask_free\n",
    "            keep0 = np.r_[keep0, prev_inds[0][mask == 0]] # Сохранение завершенных сдвигов перед удалением из поиска\n",
    "            keep1 = np.r_[keep1, prev_inds[1][mask == 0]]\n",
    "            # Удаление из поиска того, что дальше не двигается.\n",
    "            check_inds = np.delete(check_inds, np.where(mask.flatten() == 0), axis=del_axis + 1)\n",
    "            dirs = np.delete(dirs, np.where(mask.flatten() == 0), axis=del_axis)\n",
    "            cur_values = np.delete(cur_values, np.where(mask.flatten() == 0), axis=del_axis)\n",
    "            cur_values_mask = np.delete(cur_values_mask, np.where(mask.flatten() == 0), axis=del_axis)\n",
    "            mask = np.delete(mask, np.where(mask.flatten() == 0), axis=del_axis)\n",
    "\n",
    "        # Создание возвращаемых массивов.\n",
    "        moves = np.c_[keep0.reshape(-1, 1), keep1.reshape(-1, 1)]\n",
    "        if axis:\n",
    "            moves = moves[moves[:, 0].argsort(axis=0)]\n",
    "            mask = moves[:, 1] != offset\n",
    "        else:\n",
    "            moves = moves[moves[:, 1].argsort(axis=0)]\n",
    "            mask = moves[:, 0] != offset\n",
    "\n",
    "        return moves, mask\n",
    "\n",
    "    def get_offset(self, offset, direction):\n",
    "        # Возвращает смещение для направления\n",
    "        axis = np.argwhere(direction != 0)[0, 0]\n",
    "        offset = -direction[axis] * offset\n",
    "        if direction[axis] > 0:\n",
    "            offset = offset - 1\n",
    "        return offset, axis\n",
    "\n",
    "    def find_all_moves(self, state=None):\n",
    "        # Поиск всех возможных ходов для состояния.\n",
    "        moves_dict = {}\n",
    "        # Проверка направлений\n",
    "        for d in range(4):\n",
    "            direction = directions_dict[d]\n",
    "            if state is None:\n",
    "                temp_gb = self.gameboard.copy()\n",
    "            else:\n",
    "                temp_gb = state.copy()\n",
    "            already_summed_mask = np.zeros_like(temp_gb)\n",
    "            dir_dict = {}\n",
    "            moves_available = False\n",
    "            # Проверка смещений\n",
    "            for offset in range(3):\n",
    "                offset, axis = self.get_offset(offset + 1, direction)\n",
    "                moves, mask = self.find_moves(temp_gb, direction, already_summed_mask, offset)\n",
    "                dir_dict[offset] = (moves, mask)\n",
    "                if not moves_available:\n",
    "                    moves_available = np.any(mask)\n",
    "                already_summed_mask[moves[mask, 0], moves[mask, 1]] = temp_gb[moves[mask, 0], moves[mask, 1]] != 0\n",
    "                if axis:\n",
    "                    temp_gb[moves[mask, 0], moves[mask, 1]] = temp_gb[moves[mask, 0], moves[mask, 1]] + temp_gb[\n",
    "                        mask, offset]\n",
    "                    temp_gb[mask, offset] = 0\n",
    "                else:\n",
    "                    temp_gb[moves[mask, 0], moves[mask, 1]] = temp_gb[moves[mask, 0], moves[mask, 1]] + temp_gb[\n",
    "                        offset, mask]\n",
    "                    temp_gb[offset, mask] = 0\n",
    "            moves_dict[d] = (moves_available, dir_dict)\n",
    "        # Возвращает словарь {Направление : (допустимость хода в направлении, сдвигаемые ячейки)}\n",
    "        return moves_dict\n",
    "\n",
    "    def check_gameover(self, moves_dict):\n",
    "        # Проверка на конец игры\n",
    "        return not np.any([vm[0] for vm in moves_dict.values()])\n",
    "\n",
    "    def move(self, direction):\n",
    "        # Движение в заданном направлении.\n",
    "        if not self.gameover:\n",
    "            movescore = 0\n",
    "            reward = 0\n",
    "            terminal = False\n",
    "            if self.moves_dict[direction][0]:\n",
    "                # Если направление валидно\n",
    "                self.inv_move_count = 0\n",
    "                invalid_move = False\n",
    "                self.undo = self.gameboard.copy()\n",
    "                all_moves = self.moves_dict[direction][1]\n",
    "                axis = np.argwhere(directions_dict[direction] != 0)[0, 0]\n",
    "                for offset, (moves, mask) in all_moves.items():\n",
    "                    # Перемещение тайлов для каждого из трех смещений\n",
    "                    if axis:                        \n",
    "                        score_delta = self.gameboard[moves[mask, 0], moves[mask, 1]].sum()*2\n",
    "                        movescore += score_delta  # Score\n",
    "                        #if score_delta:\n",
    "                            #reward += param_join_reward * (self.gameboard[moves[mask, 0], moves[mask, 1]]!=0).sum()  \n",
    "                        # Сдвиг или суммирование на новой позиции                      \n",
    "                        self.gameboard[moves[mask, 0], moves[mask, 1]] = self.gameboard[\n",
    "                                                                             moves[mask, 0], moves[mask, 1]] + \\\n",
    "                                                                         self.gameboard[mask, offset]\n",
    "                        # Обнуление старой позиции\n",
    "                        self.gameboard[mask, offset] = 0\n",
    "                    else:                        \n",
    "                        score_delta = self.gameboard[moves[mask, 0], moves[mask, 1]].sum()*2\n",
    "                        movescore += score_delta\n",
    "                        #if score_delta:\n",
    "                            #reward += param_join_reward * (self.gameboard[moves[mask, 0], moves[mask, 1]]!=0).sum()\n",
    "                        self.gameboard[moves[mask, 0], moves[mask, 1]] = self.gameboard[\n",
    "                                                                             moves[mask, 0], moves[mask, 1]] + \\\n",
    "                                                                         self.gameboard[offset, mask]\n",
    "                        self.gameboard[offset, mask] = 0\n",
    "                # Подсчет очков\n",
    "                self.score += movescore\n",
    "                reward = movescore                \n",
    "                # Добавление случайного тайла\n",
    "                self.place_random_number()\n",
    "                # Проверка на возможность продолжения игры\n",
    "                self.moves_dict = self.find_all_moves()\n",
    "                self.gameover = self.check_gameover(self.moves_dict)\n",
    "                if self.gameover:\n",
    "                    terminal = True                    \n",
    "            else:\n",
    "                # Ход был недопустимым. Подсчет количества для invalid_move_tolerance                \n",
    "                self.inv_move_count += 1\n",
    "                invalid_move = True\n",
    "                reward = param_inv_move_reward\n",
    "            \n",
    "            return reward, terminal, invalid_move\n",
    "        else:\n",
    "            # Игра уже закончена            \n",
    "            return 0, True, False\n",
    "\n",
    "    def restore(self):\n",
    "        # Undo\n",
    "        self.gameboard = self.undo.copy()\n",
    "        self.moves_dict = self.find_all_moves()\n",
    "\n",
    "    def move_from_state(self, state, direction):\n",
    "        # Движение в заданном направлении из искусственного стейта для MCTS. (Копипэйст move(self) из-за недостатка времени)\n",
    "        state = state.copy()\n",
    "        moves_dict = self.find_all_moves(state)\n",
    "        state_gameover = self.check_gameover(moves_dict)        \n",
    "        if not state_gameover:\n",
    "            movescore = 0\n",
    "            reward = 0\n",
    "            terminal = False\n",
    "            if moves_dict[direction][0]:\n",
    "                inv_move_count = 0\n",
    "                invalid_move = False                \n",
    "                all_moves = moves_dict[direction][1]\n",
    "                axis = np.argwhere(directions_dict[direction] != 0)[0, 0]\n",
    "                for offset, (moves, mask) in all_moves.items():                    \n",
    "                    if axis:                        \n",
    "                        score_delta = state[moves[mask, 0], moves[mask, 1]].sum()*2\n",
    "                        movescore += score_delta  # Score\n",
    "                        #if score_delta:\n",
    "                            #reward += param_join_reward * (self.gameboard[moves[mask, 0], moves[mask, 1]]!=0).sum()                        \n",
    "                        state[moves[mask, 0], moves[mask, 1]] = state[moves[mask, 0], moves[mask, 1]] + \\\n",
    "                                                                         state[mask, offset]\n",
    "                        state[mask, offset] = 0\n",
    "                    else:                        \n",
    "                        score_delta = state[moves[mask, 0], moves[mask, 1]].sum()*2\n",
    "                        movescore += score_delta\n",
    "                        #if score_delta:\n",
    "                            #reward += param_join_reward * (self.gameboard[moves[mask, 0], moves[mask, 1]]!=0).sum()\n",
    "                        state[moves[mask, 0], moves[mask, 1]] = state[moves[mask, 0], moves[mask, 1]] + \\\n",
    "                                                                         state[offset, mask]\n",
    "                        state[offset, mask] = 0\n",
    "                #self.score += movescore\n",
    "                reward = movescore                \n",
    "                #self.place_random_number()\n",
    "                moves_dict = self.find_all_moves(state)\n",
    "                state_gameover = self.check_gameover(moves_dict)\n",
    "                if state_gameover:\n",
    "                    terminal = True                    \n",
    "            else:                \n",
    "                #inv_move_count += 1\n",
    "                invalid_move = True\n",
    "                reward = param_inv_move_reward\n",
    "            \n",
    "            return reward, state, terminal, invalid_move\n",
    "        else:            \n",
    "            return 0, True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UvnqHp8Skeni"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Environment. Изначально создавался под DQN (action -> reward, state, terminal) и GUI от pygame.\n",
    "Пришлось вносить срочные изменения при переходе на метод AlphaGo.\n",
    "Сейчас частично используются методы отсюда, частично из GameCore (в MCTS).\n",
    "ToDo : Привести в нормальный вид.\n",
    "\"\"\"\n",
    "class Env2048():\n",
    "    def __init__(self, gui=True, inv_move_tolerance=0):\n",
    "        self.game_core = Game_Core_2048()\n",
    "        #self.player = player\n",
    "        self.gui = None\n",
    "        if gui:\n",
    "            self.gui = Game2048(self.game_core)\n",
    "        self.inv_move_tolerance = inv_move_tolerance\n",
    "        self.inv_move_count = 0\n",
    "        #if self.player:\n",
    "         #   self.player.start()\n",
    "\n",
    "#    def draw_game(self):\n",
    "#        self.game.surface.fill(colors.AZURE3)\n",
    "\n",
    "        #self.handle_events()\n",
    "#        self.game.update()\n",
    "#        self.game.draw()\n",
    "#        pygame.display.update()\n",
    "#        self.game.clock.tick(self.game.frame_rate)\n",
    "\n",
    "    def reset(self, random_start=0., max_number=128):\n",
    "        self.game_core.reset(random_start, max_number)\n",
    "        self.inv_move_count = 0\n",
    "\n",
    "    def get_state(self):\n",
    "        state = self.game_core.gameboard.copy()              \n",
    "        return state\n",
    "\n",
    "    def act(self, action_ohe, ohe_state):\n",
    "        direction = ohe_to_dir(action_ohe)\n",
    "        state = self.get_state()\n",
    "        reward, terminal, invalid_move = self.game_core.move(direction)\n",
    "        new_state = self.get_state()\n",
    "        if not invalid_move:\n",
    "            self.inv_move_count = 0\n",
    "            if self.gui:\n",
    "                self.gui.move()\n",
    "        else:\n",
    "            self.inv_move_count += 1            \n",
    "            if self.inv_move_tolerance and self.inv_move_count >= self.inv_move_tolerance:\n",
    "                terminal = True\n",
    "        return state, action_ohe, reward, new_state, terminal\n",
    "\n",
    "    def act_from_state(self, state, direction):        \n",
    "        reward, new_state, terminal, invalid_move = self.game_core.move_from_state(direction)        \n",
    "        if invalid_move:\n",
    "            terminal = True            \n",
    "        return reward, new_state, terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oMCcUzM76rQP"
   },
   "outputs": [],
   "source": [
    "# Node для MCTS\n",
    "class TreeNode():\n",
    "    def __init__(self, game_core, state, reward, player, net, parent=None, parent_a=-1, terminal=False):\n",
    "        self.game_core = game_core\n",
    "        self.player = player\n",
    "        self.state = state\n",
    "        self.movescore = reward\n",
    "        self.parent = parent\n",
    "        self.parent_a = parent_a\n",
    "        \n",
    "        if self.player:\n",
    "            # Получение p и v от сети\n",
    "            with torch.no_grad():\n",
    "                self.P, self.v, _ = net(torch.Tensor(state_to_ohe(state)).unsqueeze(0).to(device))\n",
    "                self.P = self.P.detach().cpu().numpy().reshape(-1)\n",
    "                self.v = self.v.detach().cpu().item()\n",
    "            if parent is None:\n",
    "                self.P = self.P*0.75 + np.random.dirichlet((0.03,0.03,0.03,0.03))*0.25\n",
    "            self.N = np.zeros(4)\n",
    "            self.Q = np.zeros(4)\n",
    "        else:\n",
    "            # Распределение вероятностей появления случайных тайлов для p, если ход не игрока. \n",
    "            freecells = np.argwhere(self.state == 0)            \n",
    "            self.P = np.array([0.9]*len(freecells) + [0.1]*len(freecells)) / len(freecells)\n",
    "            self.v = 0.\n",
    "            self.N = np.zeros(len(freecells)*2)\n",
    "            self.Q = np.zeros(len(freecells)*2)\n",
    "        self.V = 0.\n",
    "        self.c_puct = 1\n",
    "        self.number_of_visits = 0\n",
    "        self.terminal = terminal        \n",
    "        self.children = {}\n",
    "        self.has_children = False        \n",
    "\n",
    "    def get_pi(self, tau=1.):\n",
    "        # Возвращает policy\n",
    "        pi = self.N**(1./tau) / (self.N**(1./tau)).sum()\n",
    "        return pi\n",
    "\n",
    "    def find_node(self, action, state):\n",
    "        # Возвращает нод с состоянием\n",
    "        if not self.player:\n",
    "            return None\n",
    "        if self.has_children:\n",
    "            if action in self.children.keys():                \n",
    "                node = self.children[action]\n",
    "                if node.has_children:\n",
    "                    for k, v in node.children.items():\n",
    "                        if np.all(state == v.state):\n",
    "                            return v                \n",
    "        return None\n",
    "\n",
    "    def make_root(self):        \n",
    "        # Делает нод корнем\n",
    "        self.movescore = 0\n",
    "        self.parent = None\n",
    "        self.parent_a = -1\n",
    "        self.P = self.P*0.75 + np.random.dirichlet((0.03,0.03,0.03,0.03))*0.25\n",
    "\n",
    "    def select_child(self):\n",
    "        # Выбирает куда идти по UCB\n",
    "        if self.terminal:            \n",
    "            return self, True\n",
    "\n",
    "        if self.player:            \n",
    "            U = self.Q + self.c_puct*self.P*(np.sqrt(self.N.sum())/(1+self.N))            \n",
    "            action = np.argmax(U)                  \n",
    "        else:\n",
    "            action = np.random.choice(np.arange(len(self.P)), p = self.P)\n",
    "        \n",
    "        self.N[action] += 1\n",
    "        if self.has_children:\n",
    "            if action in self.children.keys():                \n",
    "                return self.children[action], False\n",
    "            else:                \n",
    "                return self.expand(action), True\n",
    "        else:            \n",
    "            return self.expand(action), True\n",
    "\n",
    "    def expand(self, action):\n",
    "        # Создание нового нода\n",
    "        if self.player:\n",
    "            reward, new_state, terminal, invalid_move = self.game_core.move_from_state(self.state, action)\n",
    "            if invalid_move:\n",
    "                terminal = True            \n",
    "            self.children[action] = TreeNode(self.game_core, new_state, self.movescore+reward, not self.player, net, self, action, terminal)\n",
    "        else:\n",
    "            new_state, terminal = self.game_core.place_number(action, self.state)            \n",
    "            self.children[action] = TreeNode(self.game_core, new_state, self.movescore, not self.player, net, self, action, terminal)\n",
    "        self.has_children = True        \n",
    "        return self.children[action]\n",
    "\n",
    "    def play_to_leaf(self):\n",
    "        # Проход от корня до создания нода (итерация MCTS)        \n",
    "        node = self\n",
    "        search_finished = False\n",
    "        while not search_finished:\n",
    "            node, search_finished = node.select_child()            \n",
    "        return node\n",
    "\n",
    "    def backup(self, leaf):\n",
    "        # Обновление параметров\n",
    "        leaf.number_of_visits += 1        \n",
    "        value = leaf.v\n",
    "        movescore = leaf.movescore\n",
    "        parent_a = leaf.parent_a\n",
    "        node = leaf.parent\n",
    "        while node is not None:            \n",
    "            node.number_of_visits +=1            \n",
    "            if node.player:                \n",
    "                node.V += value                \n",
    "                node.Q[parent_a] = ((node.N[parent_a] - 1) * node.Q[parent_a] + value) / node.N[parent_a]\n",
    "            parent_a = node.parent_a\n",
    "            node = node.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tiP5wjAxgZzA"
   },
   "outputs": [],
   "source": [
    "def tree_search(root, state, net, number):\n",
    "    # Поиск по дереву из состояния заданное число раз    \n",
    "    for i in range(number):\n",
    "        leaf = root.play_to_leaf() # Проход до нового листа (Select, Expand)        \n",
    "        leaf.backup(leaf) # Backup\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Je4ASjGzGje7"
   },
   "outputs": [],
   "source": [
    "def self_play(net, dataset_size=4096, num_MCTS=999, random_start=0., max_number=128):\n",
    "    # Self-play по алгоритму Alpha Zero для создания датасета для обучения сети.\n",
    "    dataset = []    \n",
    "    env = Env2048(gui=False, inv_move_tolerance=1)\n",
    "\n",
    "    total_score = 0\n",
    "    total_num_moves = 0\n",
    "    total_inv_moves = 0\n",
    "    mean_score = 0.\n",
    "    mean_num_moves = 0.\n",
    "    total_max_num_reached = 0\n",
    "    total_num_moves = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "    i = 0\n",
    "    while len(dataset) < dataset_size:\n",
    "        i += 1\n",
    "        print(\"Simulation {}, dataset length {}\".format(i, len(dataset)))\n",
    "        env.reset(random_start, max_number)\n",
    "        terminal = False     \n",
    "        tau = 1. # Температура\n",
    "        num_moves = 0    \n",
    "        dataset_sim = []\n",
    "        dataset_sim_double = []\n",
    "        state = env.get_state()\n",
    "        root = TreeNode(Game_Core_2048(), state, 0, True, net)\n",
    "        print(\"Max number started: \", np.max(state))\n",
    "        while not terminal:        \n",
    "            state = env.get_state()            \n",
    "            pi = tree_search(root, state, net, num_MCTS).get_pi(tau) # Создание policy\n",
    "            direction_n = np.random.choice(np.arange(len(pi)), p=pi)\n",
    "            direction = dir_to_ohe(direction_n)\n",
    "            cur_score = env.game_core.score\n",
    "            # Заполнение датасета с аугментацией\n",
    "            dataset_sim.append([state_to_ohe(state), pi, cur_score]) \n",
    "            dataset_sim_double.append([state_to_ohe(state*2), pi, cur_score*2]) \n",
    "            h_flip_pi = pi.copy()\n",
    "            h_flip_pi[0], h_flip_pi[2] = h_flip_pi[2], h_flip_pi[0] \n",
    "            dataset_sim.append([state_to_ohe(np.fliplr(state)), h_flip_pi, cur_score]) \n",
    "            dataset_sim_double.append([state_to_ohe(np.fliplr(state*2)), h_flip_pi, cur_score*2]) \n",
    "            v_flip_pi = pi.copy()\n",
    "            v_flip_pi[1], v_flip_pi[3] = v_flip_pi[3], v_flip_pi[1] \n",
    "            dataset_sim.append([state_to_ohe(np.flipud(state)), v_flip_pi, cur_score]) \n",
    "            dataset_sim_double.append([state_to_ohe(np.flipud(state*2)), v_flip_pi, cur_score*2]) \n",
    "            rot90_state = np.rot90(state)\n",
    "            rot90_pi = np.roll(pi, -1)\n",
    "            dataset_sim.append([state_to_ohe(rot90_state), rot90_pi, cur_score]) \n",
    "            dataset_sim_double.append([state_to_ohe(rot90_state*2), rot90_pi, cur_score*2]) \n",
    "            h_flip_pi = rot90_pi.copy()\n",
    "            h_flip_pi[0], h_flip_pi[2] = h_flip_pi[2], h_flip_pi[0] \n",
    "            dataset_sim.append([state_to_ohe(np.fliplr(rot90_state)), h_flip_pi, cur_score]) \n",
    "            dataset_sim_double.append([state_to_ohe(np.fliplr(rot90_state*2)), h_flip_pi, cur_score*2]) \n",
    "            v_flip_pi = rot90_pi.copy()\n",
    "            v_flip_pi[1], v_flip_pi[3] = v_flip_pi[3], v_flip_pi[1] \n",
    "            dataset_sim.append([state_to_ohe(np.flipud(rot90_state)), v_flip_pi, cur_score]) \n",
    "            dataset_sim_double.append([state_to_ohe(np.flipud(rot90_state*2)), v_flip_pi, cur_score*2]) \n",
    "            dataset_sim.append([state_to_ohe(np.rot90(state, 2)), np.roll(pi, -2), cur_score]) \n",
    "            dataset_sim_double.append([state_to_ohe(np.rot90(state*2, 2)), np.roll(pi, -2), cur_score*2]) \n",
    "            dataset_sim.append([state_to_ohe(np.rot90(state, 3)), np.roll(pi, -3), cur_score]) \n",
    "            dataset_sim_double.append([state_to_ohe(np.rot90(state*2, 3)), np.roll(pi, -3), cur_score*2]) \n",
    "\n",
    "            _, _, reward, new_state, terminal = env.act(direction, ohe_state=False)      \n",
    "            new_root = root.find_node(direction_n, new_state) # Reuse дерева\n",
    "            if new_root:                \n",
    "                root = new_root\n",
    "                root.make_root()\n",
    "            else:                \n",
    "                root = TreeNode(Game_Core_2048(), new_state, 0, True, net)            \n",
    "            num_moves += 1\n",
    "            if num_moves > 30:\n",
    "                tau = 0.1\n",
    "            if reward == param_inv_move_reward:\n",
    "                total_inv_moves += 1                \n",
    "\n",
    "        cur_score = env.game_core.score\n",
    "        for data in dataset_sim:\n",
    "            data[2] = np.log1p(cur_score - data[2])\n",
    "        for data in dataset_sim_double:\n",
    "            data[2] = np.log1p(cur_score*2 - data[2])\n",
    "        dataset += dataset_sim\n",
    "        dataset += dataset_sim_double\n",
    "        with open(os.path.join(PATH, \"dataset.pickle\"), \"wb\") as f:\n",
    "            pickle.dump(dataset, f)\n",
    "        total_score += cur_score\n",
    "        total_num_moves += num_moves\n",
    "        total_max_num_reached += np.max(new_state)\n",
    "        print(\"Max number reached: {}, moves made: {}, score: {}\".format(np.max(new_state), num_moves, cur_score))\n",
    "        print(\"Time: \", (time.time() - start_time)/60.)\n",
    "\n",
    "    mean_score = total_score/i\n",
    "    mean_num_moves = total_num_moves/i\n",
    "    mean_max_num_reached = total_max_num_reached/i\n",
    "    mean_inv_moves = total_inv_moves/total_num_moves\n",
    "        \n",
    "    return dataset, (mean_score, mean_num_moves, mean_max_num_reached, mean_inv_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kTRXboUek9xB"
   },
   "outputs": [],
   "source": [
    "# Сеть по образцу из статьи.\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.action_size = param_n_actions\n",
    "        self.conv1 = nn.Conv2d(14, 128, 3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "\n",
    "    def forward(self, s):        \n",
    "        s = F.relu(self.bn1(self.conv1(s)))\n",
    "        return s\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, inplanes=128, planes=128, stride=1, downsample=None):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ConvBlockWider(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBlockWider, self).__init__()        \n",
    "        self.conv1 = nn.Conv2d(14, 256, 3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(256)\n",
    "\n",
    "    def forward(self, s):        \n",
    "        s = F.relu(self.bn1(self.conv1(s)))\n",
    "        return s\n",
    "\n",
    "class ResBlockWider(nn.Module):\n",
    "    def __init__(self, inplanes=256, planes=256, stride=1, downsample=None):\n",
    "        super(ResBlockWider, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class OutBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OutBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(256, 14, kernel_size=1) \n",
    "        self.bn = nn.BatchNorm2d(14)\n",
    "        self.fc1 = nn.Linear(14*4*4, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(256, 32, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=-1)\n",
    "        self.fc = nn.Linear(32*4*4, param_n_actions)\n",
    "    \n",
    "    def forward(self,s):\n",
    "        v = F.relu(self.bn(self.conv(s))) \n",
    "        v = v.view(-1, 14*4*4)  \n",
    "        v = F.relu(self.fc1(v))\n",
    "        v = F.relu(self.fc2(v))\n",
    "        \n",
    "        p = F.relu(self.bn1(self.conv1(s))) \n",
    "        p = p.view(-1, 32*4*4)\n",
    "        p_logits = self.fc(p)        \n",
    "        p_probas = self.logsoftmax(p_logits).exp()        \n",
    "        return p_probas, v, p_logits\n",
    "\n",
    "class Alpha2048net(nn.Module):\n",
    "    def __init__(self, device=\"cpu\"):\n",
    "        super(Alpha2048net, self).__init__()\n",
    "        #self.conv = ConvBlock()\n",
    "        self.conv = ConvBlockWider()\n",
    "        #for block in range(19):\n",
    "        for block in range(3):\n",
    "            #setattr(self, \"res_%i\" % block, ResBlock())\n",
    "            setattr(self, \"res_%i\" % block, ResBlockWider())\n",
    "        self.outblock = OutBlock()\n",
    "        self.to(device)\n",
    "    \n",
    "    def forward(self,s):\n",
    "        s = self.conv(s)\n",
    "        #for block in range(19):\n",
    "        for block in range(3):\n",
    "            s = getattr(self, \"res_%i\" % block)(s)\n",
    "        s = self.outblock(s)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "vTUq_gj7doxn",
    "outputId": "4c333425-e7b1-415c-ee69-6c969c020a89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net = Alpha2048net(device=device)\n",
    "net_optim = optim.Adam(net.parameters(), lr=1e-6, weight_decay=1e-5)\n",
    "net.eval()\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "HL9wQIajMNC6",
    "outputId": "e064f04b-b534-48a9-e10e-daddde6eb55a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(os.path.join(PATH, \"net_wider3_weights_dataset_18-wider3-32768.pth\"), map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BwV3yBO2NyiX",
    "outputId": "06023d8e-b5ab-4efd-d339-258f2b59a844"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation 1, dataset length 0\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 63, score: 428\n",
      "Time:  6.480619430541992\n",
      "Simulation 2, dataset length 1008\n",
      "Max number started:  128\n",
      "Max number reached: 256, moves made: 48, score: 592\n",
      "Time:  12.481745676199596\n",
      "Simulation 3, dataset length 1776\n",
      "Max number started:  128\n",
      "Max number reached: 128, moves made: 24, score: 132\n",
      "Time:  15.46567670504252\n",
      "Simulation 4, dataset length 2160\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 41, score: 248\n",
      "Time:  20.26848164399465\n",
      "Simulation 5, dataset length 2816\n",
      "Max number started:  256\n",
      "Max number reached: 512, moves made: 42, score: 760\n",
      "Time:  26.14280281464259\n",
      "Simulation 6, dataset length 3488\n",
      "Max number started:  4\n",
      "Max number reached: 128, moves made: 130, score: 1280\n",
      "Time:  46.839362347126006\n",
      "Simulation 7, dataset length 5568\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 70, score: 528\n",
      "Time:  57.048868318398796\n",
      "Simulation 8, dataset length 6688\n",
      "Max number started:  2\n",
      "Max number reached: 128, moves made: 145, score: 1372\n",
      "Time:  79.4485209107399\n",
      "Simulation 9, dataset length 9008\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 31, score: 396\n",
      "Time:  83.21454399426779\n",
      "Simulation 10, dataset length 9504\n",
      "Max number started:  128\n",
      "Max number reached: 256, moves made: 59, score: 592\n",
      "Time:  91.69967386722564\n",
      "Simulation 11, dataset length 10448\n",
      "Max number started:  128\n",
      "Max number reached: 512, moves made: 36, score: 1256\n",
      "Time:  96.72358852624893\n",
      "Simulation 12, dataset length 11024\n",
      "Max number started:  128\n",
      "Max number reached: 256, moves made: 106, score: 1556\n",
      "Time:  112.92756068706512\n",
      "Simulation 13, dataset length 12720\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 64, score: 668\n",
      "Time:  122.49643845160803\n",
      "Simulation 14, dataset length 13744\n",
      "Max number started:  64\n",
      "Max number reached: 64, moves made: 50, score: 356\n",
      "Time:  129.90218716859818\n",
      "Simulation 15, dataset length 14544\n",
      "Max number started:  128\n",
      "Max number reached: 128, moves made: 49, score: 376\n",
      "Time:  137.28504438400267\n",
      "Simulation 16, dataset length 15328\n",
      "Max number started:  2\n",
      "Max number reached: 64, moves made: 79, score: 576\n",
      "Time:  150.15946720838548\n",
      "Simulation 17, dataset length 16592\n",
      "Max number started:  2\n",
      "Max number reached: 256, moves made: 197, score: 2332\n",
      "Time:  181.93760761817296\n",
      "Simulation 18, dataset length 19744\n",
      "Max number started:  4\n",
      "Max number reached: 128, moves made: 139, score: 1352\n",
      "Time:  203.47513067324957\n",
      "Simulation 19, dataset length 21968\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 27, score: 140\n",
      "Time:  207.6405255238215\n",
      "Simulation 20, dataset length 22400\n",
      "Max number started:  256\n",
      "Max number reached: 512, moves made: 43, score: 1216\n",
      "Time:  212.98774445851643\n",
      "Simulation 21, dataset length 23088\n",
      "Max number started:  2\n",
      "Max number reached: 64, moves made: 65, score: 456\n",
      "Time:  222.8701495250066\n",
      "Simulation 22, dataset length 24128\n",
      "Max number started:  2\n",
      "Max number reached: 64, moves made: 107, score: 884\n",
      "Time:  239.54583487908045\n",
      "Simulation 23, dataset length 25840\n",
      "Max number started:  256\n",
      "Max number reached: 512, moves made: 17, score: 616\n",
      "Time:  241.79301830530167\n",
      "Simulation 24, dataset length 26112\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 18, score: 76\n",
      "Time:  243.24588424364725\n",
      "Simulation 25, dataset length 26400\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 12, score: 64\n",
      "Time:  244.72610385815304\n",
      "Simulation 26, dataset length 26592\n",
      "Max number started:  64\n",
      "Max number reached: 128, moves made: 69, score: 752\n",
      "Time:  254.49365558624268\n",
      "Simulation 27, dataset length 27696\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 14, score: 36\n",
      "Time:  255.54826016823452\n",
      "Simulation 28, dataset length 27920\n",
      "Max number started:  128\n",
      "Max number reached: 128, moves made: 29, score: 120\n",
      "Time:  258.75536161263784\n",
      "Simulation 29, dataset length 28384\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 76, score: 740\n",
      "Time:  270.4760548949242\n",
      "Simulation 30, dataset length 29600\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 31, score: 204\n",
      "Time:  274.4335724989573\n",
      "Simulation 31, dataset length 30096\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 20, score: 332\n",
      "Time:  276.45873821576436\n",
      "Simulation 32, dataset length 30416\n",
      "Max number started:  64\n",
      "Max number reached: 64, moves made: 13, score: 28\n",
      "Time:  277.6545295794805\n",
      "Simulation 33, dataset length 30624\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 71, score: 588\n",
      "Time:  288.42903011639913\n",
      "Simulation 34, dataset length 31760\n",
      "Max number started:  8\n",
      "Max number reached: 16, moves made: 26, score: 92\n",
      "Time:  292.60807037353516\n",
      "Simulation 35, dataset length 32176\n",
      "Max number started:  256\n",
      "Max number reached: 512, moves made: 29, score: 740\n",
      "Time:  296.75357725222904\n",
      "Simulation 36, dataset length 32640\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 16, score: 296\n",
      "Time:  299.00318008263906\n",
      "Simulation 37, dataset length 32896\n",
      "Max number started:  4\n",
      "Max number reached: 128, moves made: 152, score: 1424\n",
      "Time:  323.01194280783335\n",
      "Simulation 38, dataset length 35328\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 30, score: 196\n",
      "Time:  326.49955651760104\n",
      "Simulation 39, dataset length 35808\n",
      "Max number started:  2\n",
      "Max number reached: 128, moves made: 114, score: 1056\n",
      "Time:  344.50655017296475\n",
      "Simulation 40, dataset length 37632\n",
      "Max number started:  2\n",
      "Max number reached: 64, moves made: 74, score: 508\n",
      "Time:  356.5095416903496\n",
      "Simulation 41, dataset length 38816\n",
      "Max number started:  2\n",
      "Max number reached: 128, moves made: 112, score: 1032\n",
      "Time:  374.33765170971554\n",
      "Simulation 42, dataset length 40608\n",
      "Max number started:  2\n",
      "Max number reached: 128, moves made: 131, score: 1196\n",
      "Time:  394.8924265146255\n",
      "Simulation 43, dataset length 42704\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 72, score: 1028\n",
      "Time:  403.7968024174372\n",
      "Simulation 44, dataset length 43856\n",
      "Max number started:  256\n",
      "Max number reached: 512, moves made: 17, score: 564\n",
      "Time:  406.23750409285225\n",
      "Simulation 45, dataset length 44128\n",
      "Max number started:  128\n",
      "Max number reached: 128, moves made: 75, score: 620\n",
      "Time:  416.8423249165217\n",
      "Simulation 46, dataset length 45328\n",
      "Max number started:  128\n",
      "Max number reached: 128, moves made: 53, score: 360\n",
      "Time:  424.29706115722655\n",
      "Simulation 47, dataset length 46176\n",
      "Max number started:  2\n",
      "Max number reached: 32, moves made: 56, score: 292\n",
      "Time:  433.5682542483012\n",
      "Simulation 48, dataset length 47072\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 47, score: 256\n",
      "Time:  441.0787489771843\n",
      "Simulation 49, dataset length 47824\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 25, score: 272\n",
      "Time:  443.72729941209155\n",
      "Simulation 50, dataset length 48224\n",
      "Max number started:  2\n",
      "Max number reached: 128, moves made: 126, score: 1264\n",
      "Time:  463.7890505115191\n",
      "Simulation 51, dataset length 50240\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 34, score: 304\n",
      "Time:  468.11700245936714\n",
      "Simulation 52, dataset length 50784\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 17, score: 72\n",
      "Time:  470.39460862080256\n",
      "Simulation 53, dataset length 51056\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 50, score: 440\n",
      "Time:  478.07694341341653\n",
      "Simulation 54, dataset length 51856\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 20, score: 112\n",
      "Time:  480.28168691794076\n",
      "Simulation 55, dataset length 52176\n",
      "Max number started:  32\n",
      "Max number reached: 32, moves made: 25, score: 92\n",
      "Time:  484.3005348324776\n",
      "Simulation 56, dataset length 52576\n",
      "Max number started:  4\n",
      "Max number reached: 128, moves made: 136, score: 1336\n",
      "Time:  506.7959971904755\n",
      "Simulation 57, dataset length 54752\n",
      "Max number started:  2\n",
      "Max number reached: 32, moves made: 56, score: 332\n",
      "Time:  515.9241324663162\n",
      "Simulation 58, dataset length 55648\n",
      "Max number started:  256\n",
      "Max number reached: 512, moves made: 24, score: 664\n",
      "Time:  518.8262263894081\n",
      "Simulation 59, dataset length 56032\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 24, score: 104\n",
      "Time:  522.0846983234088\n",
      "Simulation 60, dataset length 56416\n",
      "Max number started:  256\n",
      "Max number reached: 512, moves made: 81, score: 1328\n",
      "Time:  533.8269757707914\n",
      "Simulation 61, dataset length 57712\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 65, score: 696\n",
      "Time:  543.1779234806696\n",
      "Simulation 62, dataset length 58752\n",
      "Max number started:  256\n",
      "Max number reached: 256, moves made: 26, score: 184\n",
      "Time:  545.3503842989604\n",
      "Simulation 63, dataset length 59168\n",
      "Max number started:  2\n",
      "Max number reached: 64, moves made: 86, score: 620\n",
      "Time:  558.916793223222\n",
      "Simulation 64, dataset length 60544\n",
      "Max number started:  4\n",
      "Max number reached: 64, moves made: 96, score: 764\n",
      "Time:  573.3753792881965\n",
      "Simulation 65, dataset length 62080\n",
      "Max number started:  2\n"
     ]
    }
   ],
   "source": [
    "# Генерация датасета из игр.\n",
    "#start_time = time.time()\n",
    "dataset, stats = self_play(net, dataset_size=65536, num_MCTS=512, random_start=0.75, max_number=256)\n",
    "\n",
    "with open(os.path.join(PATH, \"dataset.pickle\"), \"wb\") as f:\n",
    "    pickle.dump(dataset, f)\n",
    "\n",
    "print(\"Mean score {:.3f}, mean number of moves {:.3f}, mean max number {:.3f}, invalid moves ratio {:.3f}\".format(*stats))\n",
    "#print(\"Time: \", (time.time() - start_time)/60.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VQ6w1lyB92-j"
   },
   "outputs": [],
   "source": [
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uh-w-hZuuVLK"
   },
   "outputs": [],
   "source": [
    "def train(epoch, net, optim, loader, log):\n",
    "    net.train()\n",
    "    mean_loss = 0.\n",
    "    for data, label in loader:\n",
    "        optim.zero_grad()\n",
    "        data = data.to(device)\n",
    "        label_pi = label[:,:-1].to(device)        \n",
    "        label_z = label[:,-1].to(device).view(-1, 1)\n",
    "        p, v, p_logits = net(data)\n",
    "                \n",
    "        loss_p = torch.sum((-label_pi * (1e-8 + p).log()), 1) # Policy loss        \n",
    "        loss_v =  ((label_z - v)**2).view(-1) # Value loss        \n",
    "        loss = (loss_p + loss_v).mean()\n",
    "        \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        mean_loss += loss.item()        \n",
    "    \n",
    "    mean_loss /= len(loader)\n",
    "    log[\"train\"].append(mean_loss)\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch {} loss: {:.3f}\".format(epoch, mean_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RrHDEut-Rn9a"
   },
   "outputs": [],
   "source": [
    "def validate(epoch, net, loader, log):\n",
    "    net.eval()\n",
    "    mean_loss = 0.\n",
    "    for data, label in loader:        \n",
    "        data = data.to(device)\n",
    "        label_pi = label[:,:-1].to(device)        \n",
    "        label_z = label[:,-1].to(device).view(-1, 1)\n",
    "        p, v, p_logits = net(data)        \n",
    "        \n",
    "        loss_p = torch.sum((-label_pi * (1e-8 + p).log()), 1)        \n",
    "        loss_v =  ((label_z - v)**2).view(-1)\n",
    "        loss = (loss_p + loss_v).mean()\n",
    "        mean_loss += loss.item()        \n",
    "    \n",
    "    mean_loss /= len(loader)\n",
    "    log[\"val\"].append(mean_loss)\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch {} validation loss: {:.3f}\".format(epoch, mean_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K0BiQ1VXn1SZ"
   },
   "outputs": [],
   "source": [
    "# Создание pytorch loaders\n",
    "#np.random.shuffle(dataset)\n",
    "#split_idx = int(len(dataset)*.75)\n",
    "dataset_train = dataset#[:split_idx]\n",
    "#dataset_test = dataset[split_idx:]\n",
    "dataset_train_T = list(zip(*dataset_train))\n",
    "#dataset_test_T = list(zip(*dataset_test))\n",
    "\n",
    "data_state_train = torch.Tensor(dataset_train_T[0])\n",
    "data_pi_train = torch.Tensor(dataset_train_T[1])\n",
    "data_z_train = torch.Tensor(dataset_train_T[2]).view(-1,1)\n",
    "labels_train = torch.cat((data_pi_train, data_z_train), dim=1)\n",
    "#data_state_test = torch.Tensor(dataset_test_T[0])\n",
    "#data_pi_test = torch.Tensor(dataset_test_T[1])\n",
    "#data_z_test = torch.Tensor(dataset_test_T[2]).view(-1,1)\n",
    "#labels_test = torch.cat((data_pi_test, data_z_test), dim=1)\n",
    "\n",
    "tensor_dataset_train = TensorDataset(data_state_train, labels_train)\n",
    "loader_train = DataLoader(tensor_dataset_train, batch_size=param_batch_size, shuffle=True)\n",
    "\n",
    "#tensor_dataset_test = TensorDataset(data_state_test, labels_test)\n",
    "#loader_test = DataLoader(tensor_dataset_test, batch_size=param_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "9ZHJa1IN3FFR",
    "outputId": "c17b034c-9c9c-49e8-da3a-e044b82fd47e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 3.521\n",
      "Epoch 10 loss: 1.651\n",
      "Epoch 20 loss: 0.990\n",
      "Epoch 30 loss: 0.853\n",
      "\n"
     ]
    }
   ],
   "source": [
    "losses_log  = {\"train\" : [], \"val\" : []}\n",
    "for epoch in range(31):\n",
    "    train(epoch, net, net_optim, loader_train, losses_log)\n",
    "    #validate(epoch, net, loader_test, losses_log)\n",
    "torch.save(net.state_dict(), os.path.join(PATH, \"net_wider3_weights_dataset_18-wider3-32768.pth\"))\n",
    "net.eval()\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "tsqHaWTRnmu9",
    "outputId": "5a42fbcb-b3bc-4d61-b554-266a3bed20fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33984\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(PATH, \"dataset_18-wider3-32768.pickle\"), \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "0YUI7I2K90W4",
    "outputId": "b75dde77-47ec-430e-9668-54b4e18be9df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(os.path.join(PATH, \"net_weights_dataset_5-2048.pth\"), map_location=device))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2048Alpha.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
