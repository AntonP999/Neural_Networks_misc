{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "ikumCeWbkRlj",
    "outputId": "139d94e6-d6c8-445b-d584-069f561b2edb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "6hh61vOuzzpD",
    "outputId": "437e6bac-3439-47c6-fa4d-79a37a19fa3a"
   },
   "outputs": [],
   "source": [
    "\n",
    "PATH = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s0uMULEQkWIN"
   },
   "outputs": [],
   "source": [
    "param_join_reward = 1\n",
    "param_inv_move_reward = -8\n",
    "param_ohe_state = True\n",
    "param_input_shape = 4*4*14 if param_ohe_state else 4*4\n",
    "param_n_actions = 4\n",
    "param_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8XWuHir3kY6i"
   },
   "outputs": [],
   "source": [
    "# Направление хода -> оси\n",
    "directions_dict = {0: np.array((0,1)),\n",
    "                   1: np.array((1,0)),\n",
    "                   2: np.array((0,-1)),\n",
    "                   3: np.array((-1,0)),}\n",
    "\n",
    "# Направление в one-hot\n",
    "def dir_to_ohe(direction_int):\n",
    "    ohe = np.zeros(4)\n",
    "    ohe[direction_int] = 1\n",
    "    return ohe\n",
    "\n",
    "# Направление one-hot в int\n",
    "def ohe_to_dir(direction_ohe):\n",
    "    return np.argmax(direction_ohe)\n",
    "\n",
    "# Значение тайла в one-hot\n",
    "def tile_to_ohe(n):    \n",
    "    ohe = np.zeros(14)\n",
    "    if n>0:\n",
    "        n = int(np.log2(n))    \n",
    "        ohe[n-1] = 1\n",
    "    return ohe\n",
    "\n",
    "# Состояние в one-hot для нейросети\n",
    "def state_to_ohe(state):\n",
    "    ohe = np.zeros((4,4,14))\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            ohe[i,j] = tile_to_ohe(state[i,j])\n",
    "    return ohe.transpose((2,0,1))\n",
    "\n",
    "def position_to_tuple(position):\n",
    "    return tuple([tuple(x) for x in position])\n",
    "\n",
    "# Игровой движок\n",
    "class Game_Core_2048:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, random_start=0., max_number=128):\n",
    "        # Стандартное начало игры или со случайного состояния\n",
    "        self.gameboard = np.zeros((4, 4)).astype(int)\n",
    "        if np.random.rand() >= random_start:\n",
    "            self.place_random_number()\n",
    "            self.place_random_number()\n",
    "        else:\n",
    "            self.make_random_state(max_number)\n",
    "        #self.gameover = False\n",
    "        self.moves_dict = self.find_all_moves()\n",
    "        self.gameover = self.check_gameover(self.moves_dict)\n",
    "        self.score = 0\n",
    "        self.inv_move_count = 0\n",
    "\n",
    "    def random_free_cell(self):\n",
    "        # Возвращает случайную пустую ячейку\n",
    "        free_cells = np.argwhere(self.gameboard == 0)\n",
    "        return free_cells[np.random.randint(len(free_cells))]\n",
    "\n",
    "    def place_random_number(self):\n",
    "        # Добавление случайного тайла (по принципу как в оригинале)\n",
    "        n = 2 if np.random.rand() < 0.9 else 4\n",
    "        cell = self.random_free_cell()\n",
    "        self.gameboard[cell[0], cell[1]] = n\n",
    "\n",
    "    def place_number(self, position, state):\n",
    "        # Ставит значение в позицию (для MCTS). \n",
    "        state = state.copy()\n",
    "        free_cells = np.argwhere(state == 0)\n",
    "        number = 2\n",
    "        if position >= len(free_cells):\n",
    "            number = 4\n",
    "            position -= len(free_cells)\n",
    "        cell = free_cells[position]\n",
    "        state[cell[0], cell[1]] = number\n",
    "        moves_dict = self.find_all_moves(state)\n",
    "        state_gameover = self.check_gameover(moves_dict)\n",
    "        return state, state_gameover\n",
    "\n",
    "    def make_random_state(self, max_number):\n",
    "        # Генерирует случайную стартовую позицию.\n",
    "        idx = np.where(self.gameboard==0)\n",
    "        powers = np.random.randint(np.log2(max_number), size=(len(idx[0])))+1\n",
    "        mask = np.random.randint(2, size=(len(idx[0]))).astype(np.bool)\n",
    "        self.gameboard[idx] = 2**powers*mask\n",
    "\n",
    "    def find_moves(self, gameboard, direction, already_summed_mask, offset):\n",
    "        # Возвращает допустимые ходы в заданном направлении для заданного ряда/колонки.\n",
    "        # Пытался избежать вложенных циклов, как в оригинальной версии.\n",
    "        keep0 = []  # Хранение ходов - ось 0\n",
    "        keep1 = []  # Хранение ходов - ось 1\n",
    "        axis = np.argwhere(direction != 0)[0, 0]  # Ось направления\n",
    "        del_axis = int(not axis)  # Ось удаления найденных ходов\n",
    "\n",
    "        # Выбор параметров для горизонтального или вертикального направления.\n",
    "        if axis:\n",
    "            shape = (4, 1)\n",
    "            inds = np.indices(shape)\n",
    "            dirs = np.tile(direction[axis], 4).reshape(shape)\n",
    "            mask = np.ones(shape) # Маска для несдвигаемых тайлов.\n",
    "        else:\n",
    "            shape = (1, 4)\n",
    "            inds = np.indices(shape)\n",
    "            dirs = np.tile(direction[axis], 4).reshape(shape)\n",
    "            mask = np.ones(shape) # Маска для несдвигаемых тайлов.\n",
    "        \n",
    "        check_inds = inds.copy()  # Индексы для проверки доступного хода вдоль оси\n",
    "        check_inds[axis] = check_inds[axis] + offset  # Начало со смещения\n",
    "        mask = (mask * (gameboard[check_inds[0], check_inds[1]] != 0)).astype(bool)  # Нули не двигаем\n",
    "        keep0, keep1 = check_inds[0][mask == 0], check_inds[1][mask == 0]  # Сохранение перед удалением\n",
    "        if axis:\n",
    "            cur_values = gameboard[:, offset].reshape(shape)  # Сохранение текущих значений в ячейках\n",
    "        else:\n",
    "            cur_values = gameboard[offset, :].reshape(shape)  # Сохранение текущих значений в ячейках\n",
    "        cur_values_mask = np.ones(shape).astype(bool)\n",
    "        # Удаление из поиска того, что дальше не двигается.\n",
    "        check_inds = np.delete(check_inds, np.where(mask.flatten() == 0), axis=del_axis + 1)\n",
    "        dirs = np.delete(dirs, np.where(mask.flatten() == 0), axis=del_axis)\n",
    "        cur_values = np.delete(cur_values, np.where(mask.flatten() == 0), axis=del_axis)\n",
    "        cur_values_mask = np.delete(cur_values_mask, np.where(mask.flatten() == 0), axis=del_axis)\n",
    "        mask = np.delete(mask, np.where(mask.flatten() == 0), axis=del_axis)\n",
    "\n",
    "        # Пока что-то можно двигать дальше\n",
    "        while check_inds.size > 0:\n",
    "            cur_values[cur_values_mask] = gameboard[check_inds[0], check_inds[1]][cur_values_mask] # Сохранение текущих значений в ячейках\n",
    "            prev_inds = check_inds.copy()\n",
    "            check_inds[axis] = check_inds[axis] + dirs * mask # Смещение индексов для проверки на 1 по направлению.\n",
    "            mask = ((-direction[axis] * check_inds[axis]) >= 1 * (direction[axis] > 0)).astype(\n",
    "                bool)  # Проверка на границы поля\n",
    "            asm_mask = already_summed_mask[check_inds[0], check_inds[1]] == 0  # Проверка на уже суммированное значение (всегда первое по направлению)\n",
    "            mask = mask * asm_mask\n",
    "            new_values = gameboard[check_inds[0], check_inds[1]]  # Проверка на равенство\n",
    "            cur_values_mask = new_values != 0\n",
    "            mask_eq = mask * (cur_values == new_values)\n",
    "            mask_free = mask * (gameboard[check_inds[0], check_inds[1]] == 0)  # Проверка на свободную ячейку\n",
    "            mask = mask_eq + mask_free\n",
    "            keep0 = np.r_[keep0, prev_inds[0][mask == 0]] # Сохранение завершенных сдвигов перед удалением из поиска\n",
    "            keep1 = np.r_[keep1, prev_inds[1][mask == 0]]\n",
    "            # Удаление из поиска того, что дальше не двигается.\n",
    "            check_inds = np.delete(check_inds, np.where(mask.flatten() == 0), axis=del_axis + 1)\n",
    "            dirs = np.delete(dirs, np.where(mask.flatten() == 0), axis=del_axis)\n",
    "            cur_values = np.delete(cur_values, np.where(mask.flatten() == 0), axis=del_axis)\n",
    "            cur_values_mask = np.delete(cur_values_mask, np.where(mask.flatten() == 0), axis=del_axis)\n",
    "            mask = np.delete(mask, np.where(mask.flatten() == 0), axis=del_axis)\n",
    "\n",
    "        # Создание возвращаемых массивов.\n",
    "        moves = np.c_[keep0.reshape(-1, 1), keep1.reshape(-1, 1)]\n",
    "        if axis:\n",
    "            moves = moves[moves[:, 0].argsort(axis=0)]\n",
    "            mask = moves[:, 1] != offset\n",
    "        else:\n",
    "            moves = moves[moves[:, 1].argsort(axis=0)]\n",
    "            mask = moves[:, 0] != offset\n",
    "\n",
    "        return moves, mask\n",
    "\n",
    "    def get_offset(self, offset, direction):\n",
    "        # Возвращает смещение для направления\n",
    "        axis = np.argwhere(direction != 0)[0, 0]\n",
    "        offset = -direction[axis] * offset\n",
    "        if direction[axis] > 0:\n",
    "            offset = offset - 1\n",
    "        return offset, axis\n",
    "\n",
    "    def find_all_moves(self, state=None):\n",
    "        # Поиск всех возможных ходов для состояния.\n",
    "        moves_dict = {}\n",
    "        # Проверка направлений\n",
    "        for d in range(4):\n",
    "            direction = directions_dict[d]\n",
    "            if state is None:\n",
    "                temp_gb = self.gameboard.copy()\n",
    "            else:\n",
    "                temp_gb = state.copy()\n",
    "            already_summed_mask = np.zeros_like(temp_gb)\n",
    "            dir_dict = {}\n",
    "            moves_available = False\n",
    "            # Проверка смещений\n",
    "            for offset in range(3):\n",
    "                offset, axis = self.get_offset(offset + 1, direction)\n",
    "                moves, mask = self.find_moves(temp_gb, direction, already_summed_mask, offset)\n",
    "                dir_dict[offset] = (moves, mask)\n",
    "                if not moves_available:\n",
    "                    moves_available = np.any(mask)\n",
    "                already_summed_mask[moves[mask, 0], moves[mask, 1]] = temp_gb[moves[mask, 0], moves[mask, 1]] != 0\n",
    "                if axis:\n",
    "                    temp_gb[moves[mask, 0], moves[mask, 1]] = temp_gb[moves[mask, 0], moves[mask, 1]] + temp_gb[\n",
    "                        mask, offset]\n",
    "                    temp_gb[mask, offset] = 0\n",
    "                else:\n",
    "                    temp_gb[moves[mask, 0], moves[mask, 1]] = temp_gb[moves[mask, 0], moves[mask, 1]] + temp_gb[\n",
    "                        offset, mask]\n",
    "                    temp_gb[offset, mask] = 0\n",
    "            moves_dict[d] = (moves_available, dir_dict)\n",
    "        # Возвращает словарь {Направление : (допустимость хода в направлении, сдвигаемые ячейки)}\n",
    "        return moves_dict\n",
    "\n",
    "    def check_gameover(self, moves_dict):\n",
    "        # Проверка на конец игры\n",
    "        return not np.any([vm[0] for vm in moves_dict.values()])\n",
    "\n",
    "    def move(self, direction):\n",
    "        # Движение в заданном направлении.\n",
    "        if not self.gameover:\n",
    "            movescore = 0\n",
    "            reward = 0\n",
    "            terminal = False\n",
    "            if self.moves_dict[direction][0]:\n",
    "                # Если направление валидно\n",
    "                self.inv_move_count = 0\n",
    "                invalid_move = False\n",
    "                self.undo = self.gameboard.copy()\n",
    "                all_moves = self.moves_dict[direction][1]\n",
    "                axis = np.argwhere(directions_dict[direction] != 0)[0, 0]\n",
    "                for offset, (moves, mask) in all_moves.items():\n",
    "                    # Перемещение тайлов для каждого из трех смещений\n",
    "                    if axis:                        \n",
    "                        score_delta = self.gameboard[moves[mask, 0], moves[mask, 1]].sum()*2\n",
    "                        movescore += score_delta  # Score\n",
    "                        #if score_delta:\n",
    "                            #reward += param_join_reward * (self.gameboard[moves[mask, 0], moves[mask, 1]]!=0).sum()  \n",
    "                        # Сдвиг или суммирование на новой позиции                      \n",
    "                        self.gameboard[moves[mask, 0], moves[mask, 1]] = self.gameboard[\n",
    "                                                                             moves[mask, 0], moves[mask, 1]] + \\\n",
    "                                                                         self.gameboard[mask, offset]\n",
    "                        # Обнуление старой позиции\n",
    "                        self.gameboard[mask, offset] = 0\n",
    "                    else:                        \n",
    "                        score_delta = self.gameboard[moves[mask, 0], moves[mask, 1]].sum()*2\n",
    "                        movescore += score_delta\n",
    "                        #if score_delta:\n",
    "                            #reward += param_join_reward * (self.gameboard[moves[mask, 0], moves[mask, 1]]!=0).sum()\n",
    "                        self.gameboard[moves[mask, 0], moves[mask, 1]] = self.gameboard[\n",
    "                                                                             moves[mask, 0], moves[mask, 1]] + \\\n",
    "                                                                         self.gameboard[offset, mask]\n",
    "                        self.gameboard[offset, mask] = 0\n",
    "                # Подсчет очков\n",
    "                self.score += movescore\n",
    "                reward = movescore                \n",
    "                # Добавление случайного тайла\n",
    "                self.place_random_number()\n",
    "                # Проверка на возможность продолжения игры\n",
    "                self.moves_dict = self.find_all_moves()\n",
    "                self.gameover = self.check_gameover(self.moves_dict)\n",
    "                if self.gameover:\n",
    "                    terminal = True                    \n",
    "            else:\n",
    "                # Ход был недопустимым. Подсчет количества для invalid_move_tolerance                \n",
    "                self.inv_move_count += 1\n",
    "                invalid_move = True\n",
    "                reward = param_inv_move_reward\n",
    "            \n",
    "            return reward, terminal, invalid_move\n",
    "        else:\n",
    "            # Игра уже закончена            \n",
    "            return 0, True, False\n",
    "\n",
    "    def restore(self):\n",
    "        # Undo\n",
    "        self.gameboard = self.undo.copy()\n",
    "        self.moves_dict = self.find_all_moves()\n",
    "\n",
    "    def move_from_state(self, state, direction):\n",
    "        # Движение в заданном направлении из искусственного стейта для MCTS. (Пока копипэйст move(self) из-за недостатка времени)\n",
    "        state = state.copy()\n",
    "        moves_dict = self.find_all_moves(state)\n",
    "        state_gameover = self.check_gameover(moves_dict)        \n",
    "        if not state_gameover:\n",
    "            movescore = 0\n",
    "            reward = 0\n",
    "            terminal = False\n",
    "            if moves_dict[direction][0]:\n",
    "                inv_move_count = 0\n",
    "                invalid_move = False                \n",
    "                all_moves = moves_dict[direction][1]\n",
    "                axis = np.argwhere(directions_dict[direction] != 0)[0, 0]\n",
    "                for offset, (moves, mask) in all_moves.items():                    \n",
    "                    if axis:                        \n",
    "                        score_delta = state[moves[mask, 0], moves[mask, 1]].sum()*2\n",
    "                        movescore += score_delta  # Score\n",
    "                        #if score_delta:\n",
    "                            #reward += param_join_reward * (self.gameboard[moves[mask, 0], moves[mask, 1]]!=0).sum()                        \n",
    "                        state[moves[mask, 0], moves[mask, 1]] = state[moves[mask, 0], moves[mask, 1]] + \\\n",
    "                                                                         state[mask, offset]\n",
    "                        state[mask, offset] = 0\n",
    "                    else:                        \n",
    "                        score_delta = state[moves[mask, 0], moves[mask, 1]].sum()*2\n",
    "                        movescore += score_delta\n",
    "                        #if score_delta:\n",
    "                            #reward += param_join_reward * (self.gameboard[moves[mask, 0], moves[mask, 1]]!=0).sum()\n",
    "                        state[moves[mask, 0], moves[mask, 1]] = state[moves[mask, 0], moves[mask, 1]] + \\\n",
    "                                                                         state[offset, mask]\n",
    "                        state[offset, mask] = 0\n",
    "                #self.score += movescore\n",
    "                reward = movescore                \n",
    "                #self.place_random_number()\n",
    "                moves_dict = self.find_all_moves(state)\n",
    "                state_gameover = self.check_gameover(moves_dict)\n",
    "                if state_gameover:\n",
    "                    terminal = True                    \n",
    "            else:                \n",
    "                #inv_move_count += 1\n",
    "                invalid_move = True\n",
    "                reward = param_inv_move_reward\n",
    "            \n",
    "            return reward, state, terminal, invalid_move\n",
    "        else:            \n",
    "            return 0, True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UvnqHp8Skeni"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Environment. Изначально создавался под DQN (action -> reward, state, terminal) и GUI от pygame.\n",
    "Пришлось вносить срочные изменения при переходе на метод AlphaGo.\n",
    "Сейчас частично используются методы отсюда, частично из GameCore (в MCTS).\n",
    "ToDo : Привести в нормальный вид.\n",
    "\"\"\"\n",
    "class Env2048():\n",
    "    def __init__(self, gui=True, inv_move_tolerance=0):\n",
    "        self.game_core = Game_Core_2048()\n",
    "        #self.player = player\n",
    "        self.gui = None\n",
    "        if gui:\n",
    "            self.gui = Game2048(self.game_core)\n",
    "        self.inv_move_tolerance = inv_move_tolerance\n",
    "        self.inv_move_count = 0\n",
    "        #if self.player:\n",
    "         #   self.player.start()\n",
    "\n",
    "#    def draw_game(self):\n",
    "#        self.game.surface.fill(colors.AZURE3)\n",
    "\n",
    "        #self.handle_events()\n",
    "#        self.game.update()\n",
    "#        self.game.draw()\n",
    "#        pygame.display.update()\n",
    "#        self.game.clock.tick(self.game.frame_rate)\n",
    "\n",
    "    def reset(self, random_start=0., max_number=128):\n",
    "        self.game_core.reset(random_start, max_number)\n",
    "        self.inv_move_count = 0\n",
    "\n",
    "    def get_state(self):\n",
    "        state = self.game_core.gameboard.copy()\n",
    "        #if ohe:\n",
    "         #   state = state_to_ohe(state).transpose((2,0,1))        \n",
    "        return state\n",
    "\n",
    "    def act(self, action_ohe, ohe_state):\n",
    "        direction = ohe_to_dir(action_ohe)\n",
    "        state = self.get_state()\n",
    "        reward, terminal, invalid_move = self.game_core.move(direction)\n",
    "        new_state = self.get_state()\n",
    "        if not invalid_move:\n",
    "            self.inv_move_count = 0\n",
    "            if self.gui:\n",
    "                self.gui.move()\n",
    "        else:\n",
    "            self.inv_move_count += 1            \n",
    "            if self.inv_move_tolerance and self.inv_move_count >= self.inv_move_tolerance:\n",
    "                terminal = True\n",
    "        return state, action_ohe, reward, new_state, terminal\n",
    "\n",
    "    def act_from_state(self, state, direction):        \n",
    "        reward, new_state, terminal, invalid_move = self.game_core.move_from_state(direction)        \n",
    "        if invalid_move:\n",
    "            terminal = True            \n",
    "        return reward, new_state, terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oMCcUzM76rQP"
   },
   "outputs": [],
   "source": [
    "# Node для MCTS\n",
    "class TreeNode():\n",
    "    def __init__(self, game_core, state, reward, player, net, parent=None, parent_a=-1, terminal=False):\n",
    "        self.game_core = game_core\n",
    "        self.player = player\n",
    "        self.state = state\n",
    "        self.movescore = reward\n",
    "        self.parent = parent\n",
    "        self.parent_a = parent_a\n",
    "        \n",
    "        if self.player:\n",
    "            # Получение p и v от сети\n",
    "            with torch.no_grad():\n",
    "                self.P, self.v, _ = net(torch.Tensor(state_to_ohe(state)).unsqueeze(0).to(device))\n",
    "                self.P = self.P.detach().cpu().numpy().reshape(-1)\n",
    "                self.v = self.v.detach().cpu().item()\n",
    "            if parent is None:\n",
    "                self.P = self.P*0.75 + np.random.dirichlet((0.03,0.03,0.03,0.03))*0.25\n",
    "            self.N = np.zeros(4)\n",
    "            self.Q = np.zeros(4)\n",
    "        else:\n",
    "            # Распределение вероятностей появления случайных тайлов для p, если ход не игрока. \n",
    "            freecells = np.argwhere(self.state == 0)            \n",
    "            self.P = np.array([0.9]*len(freecells) + [0.1]*len(freecells)) / len(freecells)\n",
    "            self.v = 0.\n",
    "            self.N = np.zeros(len(freecells)*2)\n",
    "            self.Q = np.zeros(len(freecells)*2)\n",
    "        self.V = 0.\n",
    "        self.c_puct = 1\n",
    "        self.number_of_visits = 0\n",
    "        self.terminal = terminal        \n",
    "        self.children = {}\n",
    "        self.has_children = False        \n",
    "\n",
    "    def get_pi(self, tau=1.):\n",
    "        # Возвращает policy\n",
    "        pi = self.N**(1./tau) / (self.N**(1./tau)).sum()\n",
    "        return pi\n",
    "\n",
    "    def find_node(self, action, state):\n",
    "        # Возвращает нод с состоянием\n",
    "        if not self.player:\n",
    "            return None\n",
    "        if self.has_children:\n",
    "            if action in self.children.keys():                \n",
    "                node = self.children[action]\n",
    "                if node.has_children:\n",
    "                    for k, v in node.children.items():\n",
    "                        if np.all(state == v.state):\n",
    "                            return v                \n",
    "        return None\n",
    "\n",
    "    def make_root(self):        \n",
    "        # Делает нод корнем\n",
    "        self.movescore = 0\n",
    "        self.parent = None\n",
    "        self.parent_a = -1\n",
    "        self.P = self.P*0.75 + np.random.dirichlet((0.03,0.03,0.03,0.03))*0.25\n",
    "\n",
    "    def select_child(self):\n",
    "        # Выбирает куда идти по UCB\n",
    "        if self.terminal:            \n",
    "            return self, True\n",
    "\n",
    "        if self.player:            \n",
    "            U = self.Q + self.c_puct*self.P*(np.sqrt(self.N.sum())/(1+self.N))            \n",
    "            action = np.argmax(U)                  \n",
    "        else:\n",
    "            action = np.random.choice(np.arange(len(self.P)), p = self.P)\n",
    "        \n",
    "        self.N[action] += 1\n",
    "        if self.has_children:\n",
    "            if action in self.children.keys():                \n",
    "                return self.children[action], False\n",
    "            else:                \n",
    "                return self.expand(action), True\n",
    "        else:            \n",
    "            return self.expand(action), True\n",
    "\n",
    "    def expand(self, action):\n",
    "        # Создание нового нода\n",
    "        if self.player:\n",
    "            reward, new_state, terminal, invalid_move = self.game_core.move_from_state(self.state, action)\n",
    "            if invalid_move:\n",
    "                terminal = True            \n",
    "            self.children[action] = TreeNode(self.game_core, new_state, self.movescore+reward, not self.player, net, self, action, terminal)\n",
    "        else:\n",
    "            new_state, terminal = self.game_core.place_number(action, self.state)            \n",
    "            self.children[action] = TreeNode(self.game_core, new_state, self.movescore, not self.player, net, self, action, terminal)\n",
    "        self.has_children = True        \n",
    "        return self.children[action]\n",
    "\n",
    "    def play_to_leaf(self):\n",
    "        # Проход от корня до создания нода (итерация MCTS)        \n",
    "        node = self\n",
    "        search_finished = False\n",
    "        while not search_finished:\n",
    "            node, search_finished = node.select_child()            \n",
    "        return node\n",
    "\n",
    "    def backup(self, leaf):\n",
    "        # Обновление параметров\n",
    "        leaf.number_of_visits += 1        \n",
    "        value = leaf.v\n",
    "        movescore = leaf.movescore\n",
    "        parent_a = leaf.parent_a\n",
    "        node = leaf.parent\n",
    "        while node is not None:            \n",
    "            node.number_of_visits +=1            \n",
    "            if node.player:                \n",
    "                node.V += value                \n",
    "                node.Q[parent_a] = ((node.N[parent_a] - 1) * node.Q[parent_a] + value) / node.N[parent_a]\n",
    "            parent_a = node.parent_a\n",
    "            node = node.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tiP5wjAxgZzA"
   },
   "outputs": [],
   "source": [
    "def tree_search(root, state, net, number):\n",
    "    # Поиск по дереву из состояния заданное число раз    \n",
    "    for i in range(number):\n",
    "        leaf = root.play_to_leaf() # Проход до нового листа (Select, Expand)        \n",
    "        leaf.backup(leaf) # Backup\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Je4ASjGzGje7"
   },
   "outputs": [],
   "source": [
    "def self_play(net, dataset_size=4096, num_MCTS=999, random_start=0., max_number=128):\n",
    "    # Self-play по алгоритму Alpha Zero для создания датасета для обучения сети.\n",
    "    dataset = []    \n",
    "    env = Env2048(gui=False, inv_move_tolerance=1)\n",
    "\n",
    "    total_score = 0\n",
    "    total_num_moves = 0\n",
    "    total_inv_moves = 0\n",
    "    mean_score = 0.\n",
    "    mean_num_moves = 0.\n",
    "    total_max_num_reached = 0\n",
    "    total_num_moves = 0\n",
    "\n",
    "    i = 0\n",
    "    while len(dataset) < dataset_size:\n",
    "        i += 1\n",
    "        print(\"Simulation {}, dataset length {}\".format(i, len(dataset)))\n",
    "        env.reset(random_start, max_number)\n",
    "        terminal = False     \n",
    "        tau = 1. # Температура\n",
    "        num_moves = 0    \n",
    "        dataset_sim = []\n",
    "        state = env.get_state()\n",
    "        root = TreeNode(Game_Core_2048(), state, 0, True, net)\n",
    "        print(\"Max number started: \", np.max(state))\n",
    "        while not terminal:        \n",
    "            state = env.get_state()            \n",
    "            pi = tree_search(root, state, net, num_MCTS).get_pi(tau) # Создание policy\n",
    "            direction_n = np.random.choice(np.arange(len(pi)), p=pi)\n",
    "            direction = dir_to_ohe(direction_n)\n",
    "            # Заполнение датасета с аугментацией\n",
    "            dataset_sim.append([state_to_ohe(state), pi, None]) \n",
    "            h_flip_pi = pi.copy()\n",
    "            h_flip_pi[0], h_flip_pi[2] = h_flip_pi[2], h_flip_pi[0] \n",
    "            dataset_sim.append([state_to_ohe(np.fliplr(state)), h_flip_pi, None]) \n",
    "            v_flip_pi = pi.copy()\n",
    "            v_flip_pi[1], v_flip_pi[3] = v_flip_pi[3], v_flip_pi[1] \n",
    "            dataset_sim.append([state_to_ohe(np.flipud(state)), v_flip_pi, None]) \n",
    "            rot90_state = np.rot90(state)\n",
    "            rot90_pi = np.roll(pi, -1)\n",
    "            dataset_sim.append([state_to_ohe(rot90_state), rot90_pi, None]) \n",
    "            h_flip_pi = rot90_pi.copy()\n",
    "            h_flip_pi[0], h_flip_pi[2] = h_flip_pi[2], h_flip_pi[0] \n",
    "            dataset_sim.append([state_to_ohe(np.fliplr(rot90_state)), h_flip_pi, None]) \n",
    "            v_flip_pi = rot90_pi.copy()\n",
    "            v_flip_pi[1], v_flip_pi[3] = v_flip_pi[3], v_flip_pi[1] \n",
    "            dataset_sim.append([state_to_ohe(np.flipud(rot90_state)), v_flip_pi, None]) \n",
    "            dataset_sim.append([state_to_ohe(np.rot90(state, 2)), np.roll(pi, -2), None]) \n",
    "            dataset_sim.append([state_to_ohe(np.rot90(state, 3)), np.roll(pi, -3), None]) \n",
    "\n",
    "            _, _, reward, new_state, terminal = env.act(direction, ohe_state=False)      \n",
    "            new_root = root.find_node(direction_n, new_state) # Reuse дерева\n",
    "            if new_root:                \n",
    "                root = new_root\n",
    "                root.make_root()\n",
    "            else:                \n",
    "                root = TreeNode(Game_Core_2048(), new_state, 0, True, net)            \n",
    "            num_moves += 1\n",
    "            if num_moves > 30:\n",
    "                tau = 0.1\n",
    "            if reward == param_inv_move_reward:\n",
    "                total_inv_moves += 1                \n",
    "\n",
    "        cur_score = env.game_core.score\n",
    "        for data in dataset_sim:\n",
    "            data[2] = np.log1p(cur_score)\n",
    "        dataset += dataset_sim\n",
    "        with open(os.path.join(PATH, \"dataset.pickle\"), \"wb\") as f:\n",
    "            pickle.dump(dataset, f)\n",
    "        total_score += cur_score\n",
    "        total_num_moves += num_moves\n",
    "        total_max_num_reached += np.max(new_state)\n",
    "        print(\"Max number reached: \", np.max(new_state))\n",
    "\n",
    "    mean_score = total_score/i\n",
    "    mean_num_moves = total_num_moves/i\n",
    "    mean_max_num_reached = total_max_num_reached/i\n",
    "    mean_inv_moves = total_inv_moves/total_num_moves\n",
    "        \n",
    "    return dataset, (mean_score, mean_num_moves, mean_max_num_reached, mean_inv_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kTRXboUek9xB"
   },
   "outputs": [],
   "source": [
    "# Сеть по образцу из статьи.\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.action_size = param_n_actions\n",
    "        self.conv1 = nn.Conv2d(14, 128, 3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "\n",
    "    def forward(self, s):        \n",
    "        s = F.relu(self.bn1(self.conv1(s)))\n",
    "        return s\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, inplanes=128, planes=128, stride=1, downsample=None):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class OutBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OutBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(128, 3, kernel_size=1) \n",
    "        self.bn = nn.BatchNorm2d(3)\n",
    "        self.fc1 = nn.Linear(3*4*4, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(128, 32, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=-1)\n",
    "        self.fc = nn.Linear(32*4*4, param_n_actions)\n",
    "    \n",
    "    def forward(self,s):\n",
    "        v = F.relu(self.bn(self.conv(s))) \n",
    "        v = v.view(-1, 3*4*4)  \n",
    "        v = F.relu(self.fc1(v))\n",
    "        v = F.relu(self.fc2(v))\n",
    "        \n",
    "        p = F.relu(self.bn1(self.conv1(s))) \n",
    "        p = p.view(-1, 32*4*4)\n",
    "        p_logits = self.fc(p)        \n",
    "        p_probas = self.logsoftmax(p_logits).exp()        \n",
    "        return p_probas, v, p_logits\n",
    "\n",
    "class Alpha2048net(nn.Module):\n",
    "    def __init__(self, device=\"cpu\"):\n",
    "        super(Alpha2048net, self).__init__()\n",
    "        self.conv = ConvBlock()\n",
    "        for block in range(19):\n",
    "            setattr(self, \"res_%i\" % block, ResBlock())\n",
    "        self.outblock = OutBlock()\n",
    "        self.to(device)\n",
    "    \n",
    "    def forward(self,s):\n",
    "        s = self.conv(s)\n",
    "        for block in range(19):\n",
    "            s = getattr(self, \"res_%i\" % block)(s)\n",
    "        s = self.outblock(s)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "vTUq_gj7doxn",
    "outputId": "7416792e-1975-43e2-b061-7c6fce5f6df7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net = Alpha2048net(device=device)\n",
    "net_optim = optim.Adam(net.parameters(), lr=1e-5, weight_decay=1e-5)\n",
    "net.eval()\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "HL9wQIajMNC6",
    "outputId": "6d04475c-8af5-4f82-f3ed-1086cdbe7acd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(os.path.join(PATH, \"net_weights_dataset_9-1024.pth\"), map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BwV3yBO2NyiX",
    "outputId": "901c7622-207d-48ea-ed82-e6fe38ea6375"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation 1, dataset length 0\n",
      "Max number started:  64\n",
      "Max number reached:  64\n",
      "Simulation 2, dataset length 66\n",
      "Max number started:  128\n",
      "Max number reached:  256\n",
      "Simulation 3, dataset length 78\n",
      "Max number started:  2\n",
      "Max number reached:  64\n",
      "Simulation 4, dataset length 168\n",
      "Max number started:  2\n",
      "Max number reached:  64\n",
      "Simulation 5, dataset length 232\n",
      "Max number started:  2\n",
      "Max number reached:  64\n",
      "Simulation 6, dataset length 297\n",
      "Max number started:  2\n",
      "Max number reached:  8\n",
      "Simulation 7, dataset length 305\n",
      "Max number started:  32\n",
      "Max number reached:  64\n",
      "Simulation 8, dataset length 349\n",
      "Max number started:  2\n",
      "Max number reached:  128\n",
      "Simulation 9, dataset length 469\n",
      "Max number started:  128\n",
      "Max number reached:  256\n",
      "Simulation 10, dataset length 508\n",
      "Max number started:  64\n",
      "Max number reached:  128\n",
      "Simulation 11, dataset length 583\n",
      "Max number started:  2\n",
      "Max number reached:  64\n",
      "Simulation 12, dataset length 679\n",
      "Max number started:  2\n",
      "Max number reached:  32\n",
      "Simulation 13, dataset length 755\n",
      "Max number started:  2\n",
      "Max number reached:  128\n",
      "Simulation 14, dataset length 886\n",
      "Max number started:  128\n",
      "Max number reached:  256\n",
      "Simulation 15, dataset length 917\n",
      "Max number started:  32\n",
      "Max number reached:  64\n",
      "Simulation 16, dataset length 961\n",
      "Max number started:  128\n",
      "Max number reached:  256\n",
      "Simulation 17, dataset length 980\n",
      "Max number started:  2\n",
      "Max number reached:  8\n",
      "Simulation 18, dataset length 988\n",
      "Max number started:  128\n",
      "Max number reached:  128\n",
      "Simulation 19, dataset length 996\n",
      "Max number started:  128\n",
      "Max number reached:  128\n",
      "Simulation 20, dataset length 1008\n",
      "Max number started:  4\n",
      "Max number reached:  128\n",
      "Simulation 21, dataset length 1143\n",
      "Max number started:  128\n",
      "Max number reached:  128\n",
      "Simulation 22, dataset length 1170\n",
      "Max number started:  64\n",
      "Max number reached:  128\n",
      "Simulation 23, dataset length 1212\n",
      "Max number started:  128\n",
      "Max number reached:  256\n",
      "Simulation 24, dataset length 1325\n",
      "Max number started:  128\n",
      "Max number reached:  128\n",
      "Simulation 25, dataset length 1366\n",
      "Max number started:  64\n",
      "Max number reached:  128\n",
      "Simulation 26, dataset length 1448\n",
      "Max number started:  64\n",
      "Max number reached:  128\n",
      "Simulation 27, dataset length 1472\n",
      "Max number started:  128\n",
      "Max number reached:  128\n",
      "Simulation 28, dataset length 1505\n",
      "Max number started:  128\n",
      "Max number reached:  256\n",
      "Simulation 29, dataset length 1553\n",
      "Max number started:  64\n",
      "Max number reached:  128\n",
      "Simulation 30, dataset length 1579\n",
      "Max number started:  128\n",
      "Max number reached:  128\n",
      "Simulation 31, dataset length 1591\n",
      "Max number started:  2\n",
      "Max number reached:  64\n",
      "Simulation 32, dataset length 1698\n",
      "Max number started:  128\n",
      "Max number reached:  256\n",
      "Simulation 33, dataset length 1726\n",
      "Max number started:  64\n",
      "Max number reached:  128\n",
      "Simulation 34, dataset length 1817\n",
      "Max number started:  2\n",
      "Max number reached:  128\n",
      "Simulation 35, dataset length 1984\n",
      "Max number started:  128\n",
      "Max number reached:  128\n",
      "Simulation 36, dataset length 1988\n",
      "Max number started:  64\n",
      "Max number reached:  128\n",
      "Simulation 37, dataset length 2040\n",
      "Max number started:  128\n",
      "Max number reached:  256\n",
      "Simulation 38, dataset length 2063\n",
      "Max number started:  64\n",
      "Max number reached:  128\n",
      "Simulation 39, dataset length 2142\n",
      "Max number started:  128\n",
      "Max number reached:  128\n",
      "Simulation 40, dataset length 2190\n",
      "Max number started:  128\n",
      "Max number reached:  256\n",
      "Simulation 41, dataset length 2222\n",
      "Max number started:  128\n",
      "Max number reached:  256\n",
      "Simulation 42, dataset length 2270\n",
      "Max number started:  64\n",
      "Max number reached:  64\n",
      "Simulation 43, dataset length 2313\n",
      "Max number started:  64\n",
      "Max number reached:  128\n",
      "Simulation 44, dataset length 2392\n",
      "Max number started:  32\n",
      "Max number reached:  64\n",
      "Simulation 45, dataset length 2441\n",
      "Max number started:  64\n",
      "Max number reached:  128\n",
      "Simulation 46, dataset length 2494\n",
      "Max number started:  128\n",
      "Max number reached:  128\n",
      "Simulation 47, dataset length 2526\n",
      "Max number started:  2\n",
      "Max number reached:  64\n",
      "Simulation 48, dataset length 2639\n",
      "Max number started:  2\n",
      "Max number reached:  64\n",
      "Simulation 49, dataset length 2745\n",
      "Max number started:  2\n"
     ]
    }
   ],
   "source": [
    "# Генерация датасета из игр.\n",
    "start_time = time.time()\n",
    "dataset, stats = self_play(net, dataset_size=4096, num_MCTS=333, random_start=0.75, max_number=128)\n",
    "\n",
    "with open(os.path.join(PATH, \"dataset.pickle\"), \"wb\") as f:\n",
    "    pickle.dump(dataset, f)\n",
    "\n",
    "print(\"Mean score {:.3f}, mean number of moves {:.3f}, mean max number {:.3f}, invalid moves ratio {:.3f}\".format(*stats))\n",
    "print(\"Time: \", (time.time() - start_time)/60.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "tsqHaWTRnmu9",
    "outputId": "b965a69f-2253-4f92-ca7a-0dcca65e893d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2745\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(PATH, \"dataset.pickle\"), \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K0BiQ1VXn1SZ"
   },
   "outputs": [],
   "source": [
    "# Создание pytorch loaders\n",
    "#np.random.shuffle(dataset)\n",
    "#split_idx = int(len(dataset)*.75)\n",
    "dataset_train = dataset#[:split_idx]\n",
    "#dataset_test = dataset[split_idx:]\n",
    "dataset_train_T = list(zip(*dataset_train))\n",
    "#dataset_test_T = list(zip(*dataset_test))\n",
    "\n",
    "data_state_train = torch.Tensor(dataset_train_T[0])\n",
    "data_pi_train = torch.Tensor(dataset_train_T[1])\n",
    "data_z_train = torch.Tensor(dataset_train_T[2]).view(-1,1)\n",
    "labels_train = torch.cat((data_pi_train, data_z_train), dim=1)\n",
    "#data_state_test = torch.Tensor(dataset_test_T[0])\n",
    "#data_pi_test = torch.Tensor(dataset_test_T[1])\n",
    "#data_z_test = torch.Tensor(dataset_test_T[2]).view(-1,1)\n",
    "#labels_test = torch.cat((data_pi_test, data_z_test), dim=1)\n",
    "\n",
    "tensor_dataset_train = TensorDataset(data_state_train, labels_train)\n",
    "loader_train = DataLoader(tensor_dataset_train, batch_size=param_batch_size, shuffle=True)\n",
    "\n",
    "#tensor_dataset_test = TensorDataset(data_state_test, labels_test)\n",
    "#loader_test = DataLoader(tensor_dataset_test, batch_size=param_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uh-w-hZuuVLK"
   },
   "outputs": [],
   "source": [
    "def train(epoch, net, optim, loader, log):\n",
    "    net.train()\n",
    "    mean_loss = 0.\n",
    "    for data, label in loader:\n",
    "        optim.zero_grad()\n",
    "        data = data.to(device)\n",
    "        label_pi = label[:,:-1].to(device)        \n",
    "        label_z = label[:,-1].to(device).view(-1, 1)\n",
    "        p, v, p_logits = net(data)\n",
    "                \n",
    "        loss_p = torch.sum((-label_pi * (1e-8 + p).log()), 1) # Policy loss        \n",
    "        loss_v =  ((label_z - v)**2).view(-1) # Value loss        \n",
    "        loss = (loss_p + loss_v).mean()\n",
    "        \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        mean_loss += loss.item()        \n",
    "    \n",
    "    mean_loss /= len(loader)\n",
    "    log[\"train\"].append(mean_loss)\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch {} loss: {:.3f}\".format(epoch, mean_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RrHDEut-Rn9a"
   },
   "outputs": [],
   "source": [
    "def validate(epoch, net, loader, log):\n",
    "    net.eval()\n",
    "    mean_loss = 0.\n",
    "    for data, label in loader:        \n",
    "        data = data.to(device)\n",
    "        label_pi = label[:,:-1].to(device)        \n",
    "        label_z = label[:,-1].to(device).view(-1, 1)\n",
    "        p, v, p_logits = net(data)        \n",
    "        \n",
    "        loss_p = torch.sum((-label_pi * (1e-8 + p).log()), 1)        \n",
    "        loss_v =  ((label_z - v)**2).view(-1)\n",
    "        loss = (loss_p + loss_v).mean()\n",
    "        mean_loss += loss.item()        \n",
    "    \n",
    "    mean_loss /= len(loader)\n",
    "    log[\"val\"].append(mean_loss)\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch {} validation loss: {:.3f}\".format(epoch, mean_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "9ZHJa1IN3FFR",
    "outputId": "2625054c-cc24-4312-ee03-f45d6829b266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 1.130\n",
      "Epoch 10 loss: 0.117\n",
      "Epoch 20 loss: 0.096\n",
      "Epoch 30 loss: 0.086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "losses_log  = {\"train\" : [], \"val\" : []}\n",
    "for epoch in range(31):\n",
    "    train(epoch, net, net_optim, loader_train, losses_log)\n",
    "    #validate(epoch, net, loader_test, losses_log)\n",
    "torch.save(net.state_dict(), os.path.join(PATH, \"net_weights_dataset_9-1024.pth\"))\n",
    "net.eval()\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "0YUI7I2K90W4",
    "outputId": "b75dde77-47ec-430e-9668-54b4e18be9df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(os.path.join(PATH, \"net_weights_dataset_5-2048.pth\"), map_location=device))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2048Alpha.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
